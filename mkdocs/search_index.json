{
    "docs": [
        {
            "location": "/api/",
            "text": "PipelineAI CLI and REST APIs\n\u00b6\n\n\nInstall Pre-Requisites\n\u00b6\n\n\nDocker\n\u00b6\n\n\n\n\nInstall \nDocker\n\n\n\n\nPython3\n\u00b6\n\n\n\n\nInstall \nMiniconda\n with Python3 Support\n\n\n\n\nSetup \npipeline-ai-cli\n\u00b6\n\n\nNote: This command line interface requires \nPython3\n and \nDocker\n. (See Pre-Requisites above.)\n\n\npip install --ignore-installed --no-cache -U pipeline-ai-cli\n\n\n\n\nSupported Model Types\n\u00b6\n\n\nscikit\n, \ntensorflow\n, \npython\n, \nkeras\n, \npmml\n, \nspark\n, \nxgboost\n, r\n\n\nMore \nsamples\n coming soon for r.\n\n\nClone this Repo\n\u00b6\n\n\nThis may take a few minutes...\n\ngit clone https://github.com/fluxcapacitor/pipeline\n\n\n\nChange to \npipeline/predict\n Directory within Cloned Repo\n\u00b6\n\n\ncd pipeline/predict\n\n\n\n\nBuild Model into Docker Image\n\u00b6\n\n\nNote:  The \n--model-path\n currently must be \nrelative\n to the \npipeline/predict\n directory.\n\npipeline model-build --model-type=tensorflow --model-name=mnist --model-tag=master --model-path=./models/tensorflow/mnist\n\n\n\nStart Docker-based Model\n\u00b6\n\n\npipeline model-start --model-type=tensorflow --model-name=mnist --model-tag=master --memory-limit=2G\n\n\nNote:  If you see \ndocker\n:\n \nError\n \nresponse\n \nfrom\n \ndaemon\n:\n \n...\n \nfailed\n:\n \nport\n \nis\n \nalready\n \nallocated\n.\n, you likely have another Docker container running.  Use \ndocker ps\n to find the container-id, then \ndocker rm -f <container-id>\n to remove the other Docker container.\n\n\nMonitor Model Training and Hyper-Parameter Tuning\n\u00b6\n\n\nView the logs and wait for them to settle down.\n\npipeline model-logs --model-type=tensorflow --model-name=mnist --model-tag=master\n\n\n\nView PipelineAI Model UI (TensorFlow Models Only)\n\u00b6\n\n\nThis UI sometimes requires a couple refreshes.  We are working to stabilize the UI.\n\n\nNote:  This UI currently works only with TensorFlow Models\n\nhttp://localhost:6333/\n\n\n\n\n\n\n\nPredict Model\n\u00b6\n\n\nCLI\n\u00b6\n\n\nPerform Single Image Prediction\n\n\nNote:  This first call will take 10-20x longer than subsequent calls.  Lazy init, warm-up, etc.\n\npipeline model-predict --model-type=tensorflow --model-name=mnist --model-tag=master --model-server-url=http://localhost:6969 --model-test-request-path=./models/tensorflow/mnist/data/test_request.json\n\n\n\nPerform 100 Predictions in Parallel\n\n\npipeline model-predict --model-type=tensorflow --model-name=mnist --model-tag=master --model-server-url=http://localhost:6969 --model-test-request-path=./models/tensorflow/mnist/data/test_request.json --model-test-request-concurrency=100\n\n\n\nREST API\n\u00b6\n\n\nPrediction Inputs\n\n\nJSON representation of gray-scale values for a given digit (5).\n\n\ncurl -X POST -H \"Content-Type: application/json\" \\\n  -d '{\"image\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05098039656877518, 0.529411792755127, 0.3960784673690796, 0.572549045085907, 0.572549045085907, 0.847058892250061, 0.8156863451004028, 0.9960784912109375, 1.0, 1.0, 0.9960784912109375, 0.5960784554481506, 0.027450982481241226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32156863808631897, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.7882353663444519, 0.11764706671237946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32156863808631897, 0.9921569228172302, 0.988235354423523, 0.7921569347381592, 0.9450981020927429, 0.545098066329956, 0.21568629145622253, 0.3450980484485626, 0.45098042488098145, 0.125490203499794, 0.125490203499794, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32156863808631897, 0.9921569228172302, 0.803921639919281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6352941393852234, 0.9921569228172302, 0.803921639919281, 0.24705883860588074, 0.3490196168422699, 0.6509804129600525, 0.32156863808631897, 0.32156863808631897, 0.1098039299249649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007843137718737125, 0.7529412508010864, 0.9921569228172302, 0.9725490808486938, 0.9686275124549866, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.8274510502815247, 0.29019609093666077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2549019753932953, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.847058892250061, 0.027450982481241226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5921568870544434, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.7333333492279053, 0.44705885648727417, 0.23137256503105164, 0.23137256503105164, 0.4784314036369324, 0.9921569228172302, 0.9921569228172302, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5568627715110779, 0.9568628072738647, 0.7098039388656616, 0.08235294371843338, 0.019607843831181526, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.43137258291244507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15294118225574493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1882353127002716, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6705882549285889, 0.9921569228172302, 0.9921569228172302, 0.12156863510608673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2392157018184662, 0.9647059440612793, 0.9921569228172302, 0.6274510025978088, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08235294371843338, 0.44705885648727417, 0.16470588743686676, 0.0, 0.0, 0.2549019753932953, 0.9294118285179138, 0.9921569228172302, 0.9333333969116211, 0.27450981736183167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176772117615, 0.9529412388801575, 0.0, 0.0, 0.5803921818733215, 0.9333333969116211, 0.9921569228172302, 0.9921569228172302, 0.4078431725502014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7411764860153198, 0.9764706492424011, 0.5529412031173706, 0.8784314393997192, 0.9921569228172302, 0.9921569228172302, 0.9490196704864502, 0.43529415130615234, 0.007843137718737125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6235294342041016, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9764706492424011, 0.6274510025978088, 0.1882353127002716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18431372940540314, 0.5882353186607361, 0.729411780834198, 0.5686274766921997, 0.3529411852359772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}' \\\n  http://localhost:6969/api/v1/model/predict/tensorflow/mnist \\\n  -w \"\\n\\n\"\n\n### EXPECTED OUTPUT ###\n\n{\"outputs\": [0.0022526539396494627, 2.63791100074684e-10, 0.4638307988643646, 0.21909376978874207, 3.2985670372909226e-07, 0.29357224702835083, 0.00019597385835368186, 5.230629176367074e-05, 0.020996594801545143, 5.426473762781825e-06]}\n\n\n\n\nPrediction Outputs\n\n\nDigit  Confidence\n=====  ==========\n0      0.0022526539396494627\n1      2.63791100074684e-10\n2      0.4638307988643646\n3      0.21909376978874207\n4      3.2985670372909226e-07\n5      0.29357224702835083 \n6      0.00019597385835368186\n7      5.230629176367074e-05\n8      0.020996594801545143\n9      5.426473762781825e-06\n\n\n\nView Live Predictions through Kafka Logger\n\u00b6\n\n\nRe-run the predictions above while watching this url:\n\nhttp://localhost:5959/\n\n\n\nMonitor Model Predictions\n\u00b6\n\n\nNote:  These dashboards will be rolled into the PipelineAI Model UI soon!\nUsername/Password: \nadmin\n/\nadmin\n\n\nUse \nhttp://localhost:9090\n for the Prometheus data source within your Grafana Dashboard.\n\n\nhttp://localhost:3000/\n\n\n\n\n\nStop Docker-based Model\n\u00b6\n\n\npipeline model-stop --model-type=tensorflow --model-name=mnist --model-tag=master\n\n\n\n\nExtras\n\u00b6\n\n\nShell into Docker-based Model\n\u00b6\n\n\npipeline model-shell --model-type=tensorflow --model-name=mnist --model-tag=master\n\n\n\n\nPush Image to Docker\n\u00b6\n\n\nLogin to your Docker Image Repository.\n\u00b6\n\n\ndocker login\n\n\n\n\nPush Docker Image\n\u00b6\n\n\npipeline model-push --model-type=tensorflow --model-name=mnist --model-tag=master\n\n\n\n\n(Optional) Create Kubernetes YAML for the Model\n\u00b6\n\n\npipeline model-yaml --model-type=tensorflow --model-name=mnist --model-tag=master\n\n### EXPECTED OUTPUT ###\nUsing templates in '/Users/cfregly/workspace-fluxcapacitor/pipeline/predict/templates'.\n(Specify --template-path if the templates live elsewhere.)\n\n'predict-deploy.yaml.template' -> './tensorflow-mnist-cpu-master-deploy.yaml'.\n'predict-svc.yaml.template' -> './tensorflow-mnist-cpu-master-svc.yaml'.\n...\n\n\n\n\n(Optional) Deploy Model to Kubernetes Using Generated YAML Above\n\u00b6\n\n\nCreate the Kubernetes Deployment\n\npipeline kube-create ./tensorflow-mnist-cpu-master-deploy.yaml\n\n\n\nCreate the Kubernetes Service (Load Balancer)\n\npipeline kube-create ./tensorflow-mnist-cpu-master-svc.yaml\n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "CLI and REST API"
        },
        {
            "location": "/api/#pipelineai-cli-and-rest-apis",
            "text": "",
            "title": "PipelineAI CLI and REST APIs"
        },
        {
            "location": "/api/#install-pre-requisites",
            "text": "",
            "title": "Install Pre-Requisites"
        },
        {
            "location": "/api/#docker",
            "text": "Install  Docker",
            "title": "Docker"
        },
        {
            "location": "/api/#python3",
            "text": "Install  Miniconda  with Python3 Support",
            "title": "Python3"
        },
        {
            "location": "/api/#setup-pipeline-ai-cli",
            "text": "Note: This command line interface requires  Python3  and  Docker . (See Pre-Requisites above.)  pip install --ignore-installed --no-cache -U pipeline-ai-cli",
            "title": "Setup pipeline-ai-cli"
        },
        {
            "location": "/api/#supported-model-types",
            "text": "scikit ,  tensorflow ,  python ,  keras ,  pmml ,  spark ,  xgboost , r  More  samples  coming soon for r.",
            "title": "Supported Model Types"
        },
        {
            "location": "/api/#clone-this-repo",
            "text": "This may take a few minutes... git clone https://github.com/fluxcapacitor/pipeline",
            "title": "Clone this Repo"
        },
        {
            "location": "/api/#change-to-pipelinepredict-directory-within-cloned-repo",
            "text": "cd pipeline/predict",
            "title": "Change to pipeline/predict Directory within Cloned Repo"
        },
        {
            "location": "/api/#build-model-into-docker-image",
            "text": "Note:  The  --model-path  currently must be  relative  to the  pipeline/predict  directory. pipeline model-build --model-type=tensorflow --model-name=mnist --model-tag=master --model-path=./models/tensorflow/mnist",
            "title": "Build Model into Docker Image"
        },
        {
            "location": "/api/#start-docker-based-model",
            "text": "pipeline model-start --model-type=tensorflow --model-name=mnist --model-tag=master --memory-limit=2G \nNote:  If you see  docker :   Error   response   from   daemon :   ...   failed :   port   is   already   allocated . , you likely have another Docker container running.  Use  docker ps  to find the container-id, then  docker rm -f <container-id>  to remove the other Docker container.",
            "title": "Start Docker-based Model"
        },
        {
            "location": "/api/#monitor-model-training-and-hyper-parameter-tuning",
            "text": "View the logs and wait for them to settle down. pipeline model-logs --model-type=tensorflow --model-name=mnist --model-tag=master",
            "title": "Monitor Model Training and Hyper-Parameter Tuning"
        },
        {
            "location": "/api/#view-pipelineai-model-ui-tensorflow-models-only",
            "text": "This UI sometimes requires a couple refreshes.  We are working to stabilize the UI.  Note:  This UI currently works only with TensorFlow Models http://localhost:6333/",
            "title": "View PipelineAI Model UI (TensorFlow Models Only)"
        },
        {
            "location": "/api/#predict-model",
            "text": "",
            "title": "Predict Model"
        },
        {
            "location": "/api/#cli",
            "text": "Perform Single Image Prediction  Note:  This first call will take 10-20x longer than subsequent calls.  Lazy init, warm-up, etc. pipeline model-predict --model-type=tensorflow --model-name=mnist --model-tag=master --model-server-url=http://localhost:6969 --model-test-request-path=./models/tensorflow/mnist/data/test_request.json  Perform 100 Predictions in Parallel  pipeline model-predict --model-type=tensorflow --model-name=mnist --model-tag=master --model-server-url=http://localhost:6969 --model-test-request-path=./models/tensorflow/mnist/data/test_request.json --model-test-request-concurrency=100",
            "title": "CLI"
        },
        {
            "location": "/api/#rest-api",
            "text": "Prediction Inputs  JSON representation of gray-scale values for a given digit (5).  curl -X POST -H \"Content-Type: application/json\" \\\n  -d '{\"image\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05098039656877518, 0.529411792755127, 0.3960784673690796, 0.572549045085907, 0.572549045085907, 0.847058892250061, 0.8156863451004028, 0.9960784912109375, 1.0, 1.0, 0.9960784912109375, 0.5960784554481506, 0.027450982481241226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32156863808631897, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.7882353663444519, 0.11764706671237946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32156863808631897, 0.9921569228172302, 0.988235354423523, 0.7921569347381592, 0.9450981020927429, 0.545098066329956, 0.21568629145622253, 0.3450980484485626, 0.45098042488098145, 0.125490203499794, 0.125490203499794, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32156863808631897, 0.9921569228172302, 0.803921639919281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6352941393852234, 0.9921569228172302, 0.803921639919281, 0.24705883860588074, 0.3490196168422699, 0.6509804129600525, 0.32156863808631897, 0.32156863808631897, 0.1098039299249649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007843137718737125, 0.7529412508010864, 0.9921569228172302, 0.9725490808486938, 0.9686275124549866, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.8274510502815247, 0.29019609093666077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2549019753932953, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.847058892250061, 0.027450982481241226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5921568870544434, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.7333333492279053, 0.44705885648727417, 0.23137256503105164, 0.23137256503105164, 0.4784314036369324, 0.9921569228172302, 0.9921569228172302, 0.03921568766236305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5568627715110779, 0.9568628072738647, 0.7098039388656616, 0.08235294371843338, 0.019607843831181526, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.43137258291244507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15294118225574493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1882353127002716, 0.9921569228172302, 0.9921569228172302, 0.46666669845581055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6705882549285889, 0.9921569228172302, 0.9921569228172302, 0.12156863510608673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2392157018184662, 0.9647059440612793, 0.9921569228172302, 0.6274510025978088, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08235294371843338, 0.44705885648727417, 0.16470588743686676, 0.0, 0.0, 0.2549019753932953, 0.9294118285179138, 0.9921569228172302, 0.9333333969116211, 0.27450981736183167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176772117615, 0.9529412388801575, 0.0, 0.0, 0.5803921818733215, 0.9333333969116211, 0.9921569228172302, 0.9921569228172302, 0.4078431725502014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7411764860153198, 0.9764706492424011, 0.5529412031173706, 0.8784314393997192, 0.9921569228172302, 0.9921569228172302, 0.9490196704864502, 0.43529415130615234, 0.007843137718737125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6235294342041016, 0.9921569228172302, 0.9921569228172302, 0.9921569228172302, 0.9764706492424011, 0.6274510025978088, 0.1882353127002716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18431372940540314, 0.5882353186607361, 0.729411780834198, 0.5686274766921997, 0.3529411852359772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}' \\\n  http://localhost:6969/api/v1/model/predict/tensorflow/mnist \\\n  -w \"\\n\\n\"\n\n### EXPECTED OUTPUT ###\n\n{\"outputs\": [0.0022526539396494627, 2.63791100074684e-10, 0.4638307988643646, 0.21909376978874207, 3.2985670372909226e-07, 0.29357224702835083, 0.00019597385835368186, 5.230629176367074e-05, 0.020996594801545143, 5.426473762781825e-06]}  Prediction Outputs  Digit  Confidence\n=====  ==========\n0      0.0022526539396494627\n1      2.63791100074684e-10\n2      0.4638307988643646\n3      0.21909376978874207\n4      3.2985670372909226e-07\n5      0.29357224702835083 \n6      0.00019597385835368186\n7      5.230629176367074e-05\n8      0.020996594801545143\n9      5.426473762781825e-06",
            "title": "REST API"
        },
        {
            "location": "/api/#view-live-predictions-through-kafka-logger",
            "text": "Re-run the predictions above while watching this url: http://localhost:5959/",
            "title": "View Live Predictions through Kafka Logger"
        },
        {
            "location": "/api/#monitor-model-predictions",
            "text": "Note:  These dashboards will be rolled into the PipelineAI Model UI soon!\nUsername/Password:  admin / admin  Use  http://localhost:9090  for the Prometheus data source within your Grafana Dashboard.  http://localhost:3000/",
            "title": "Monitor Model Predictions"
        },
        {
            "location": "/api/#stop-docker-based-model",
            "text": "pipeline model-stop --model-type=tensorflow --model-name=mnist --model-tag=master",
            "title": "Stop Docker-based Model"
        },
        {
            "location": "/api/#extras",
            "text": "",
            "title": "Extras"
        },
        {
            "location": "/api/#shell-into-docker-based-model",
            "text": "pipeline model-shell --model-type=tensorflow --model-name=mnist --model-tag=master",
            "title": "Shell into Docker-based Model"
        },
        {
            "location": "/api/#push-image-to-docker",
            "text": "",
            "title": "Push Image to Docker"
        },
        {
            "location": "/api/#login-to-your-docker-image-repository",
            "text": "docker login",
            "title": "Login to your Docker Image Repository."
        },
        {
            "location": "/api/#push-docker-image",
            "text": "pipeline model-push --model-type=tensorflow --model-name=mnist --model-tag=master",
            "title": "Push Docker Image"
        },
        {
            "location": "/api/#optional-create-kubernetes-yaml-for-the-model",
            "text": "pipeline model-yaml --model-type=tensorflow --model-name=mnist --model-tag=master\n\n### EXPECTED OUTPUT ###\nUsing templates in '/Users/cfregly/workspace-fluxcapacitor/pipeline/predict/templates'.\n(Specify --template-path if the templates live elsewhere.)\n\n'predict-deploy.yaml.template' -> './tensorflow-mnist-cpu-master-deploy.yaml'.\n'predict-svc.yaml.template' -> './tensorflow-mnist-cpu-master-svc.yaml'.\n...",
            "title": "(Optional) Create Kubernetes YAML for the Model"
        },
        {
            "location": "/api/#optional-deploy-model-to-kubernetes-using-generated-yaml-above",
            "text": "Create the Kubernetes Deployment pipeline kube-create ./tensorflow-mnist-cpu-master-deploy.yaml  Create the Kubernetes Service (Load Balancer) pipeline kube-create ./tensorflow-mnist-cpu-master-svc.yaml",
            "title": "(Optional) Deploy Model to Kubernetes Using Generated YAML Above"
        },
        {
            "location": "/api/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/api/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/api/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/runbooks/",
            "text": "AWS ECS Runbook\n\u00b6\n\n\nBuild and Test\n Your Model as a Docker Image\n\u00b6\n\n\nPush\n Docker Image to Docker Registry\n\u00b6\n\n\nSetup ECS Cluster through AWS CLI\n\u00b6\n\n\nConfigure Docker Image, RAM, and CPU\n\n\n \n\n\nConfigure Ports and Environment Variables",
            "title": "Deployment Runbooks"
        },
        {
            "location": "/runbooks/#aws-ecs-runbook",
            "text": "",
            "title": "AWS ECS Runbook"
        },
        {
            "location": "/runbooks/#build-and-test-your-model-as-a-docker-image",
            "text": "",
            "title": "Build and Test Your Model as a Docker Image"
        },
        {
            "location": "/runbooks/#push-docker-image-to-docker-registry",
            "text": "",
            "title": "Push Docker Image to Docker Registry"
        },
        {
            "location": "/runbooks/#setup-ecs-cluster-through-aws-cli",
            "text": "Configure Docker Image, RAM, and CPU     Configure Ports and Environment Variables",
            "title": "Setup ECS Cluster through AWS CLI"
        },
        {
            "location": "/model_monitor/",
            "text": "Dashboards and Visualizations\n\u00b6\n\n\nMetrics, dashboards, and visualizations are native to PipelineAI.  \n\n\nWe believe that you should have full insight into everything deployed to production.\n\n\nPipelineAI provides the usual dashboards for real-time system metrics including memory usage, disk I/O and network throughput, CPU and GPU utilization of your model training and deployment activities.\n\n\nIn addition, PipelineAI provides dashboards for real-time prediction metrics including accuracy, latency, and throughput of your models in production.\n\n\nExample Dashboards\n\u00b6\n\n\nMonitor and Optimize Model Training\n\u00b6\n\n\n\n\n\n\nStabilize the Model Server Cluster\n\u00b6\n\n\nUnhealthy or latent model servers may open a \ncircuit\n, respond with a suitable fallback, and allow the cluster to stabilize.\n\n\n\n\nOptimize Performance\n\u00b6\n\n\nLarge batch sizes provide higher throughput at the expense of latency.  PipelineAI dynamically configures the system to find the proper balance.\n\n\n\n\nControl Latency with Timeouts\n\u00b6\n\n\nHigh latency may lead to unhealthy model servers if left unbounded.  All PipelineAI service calls are bound with timeouts.\n\n\nMonitor and Alert\n\u00b6\n\n\nHigh resource utilization - beyond container and physical node limits - will certainly degrade performance.  PipelineAI monitors all system resources.\n\n\nScale Dynamically\n\u00b6\n\n\nAll PipelineAI services support auto-scaling across federated cloud and on-premise environments.\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Dashboards"
        },
        {
            "location": "/model_monitor/#dashboards-and-visualizations",
            "text": "Metrics, dashboards, and visualizations are native to PipelineAI.    We believe that you should have full insight into everything deployed to production.  PipelineAI provides the usual dashboards for real-time system metrics including memory usage, disk I/O and network throughput, CPU and GPU utilization of your model training and deployment activities.  In addition, PipelineAI provides dashboards for real-time prediction metrics including accuracy, latency, and throughput of your models in production.",
            "title": "Dashboards and Visualizations"
        },
        {
            "location": "/model_monitor/#example-dashboards",
            "text": "",
            "title": "Example Dashboards"
        },
        {
            "location": "/model_monitor/#monitor-and-optimize-model-training",
            "text": "",
            "title": "Monitor and Optimize Model Training"
        },
        {
            "location": "/model_monitor/#stabilize-the-model-server-cluster",
            "text": "Unhealthy or latent model servers may open a  circuit , respond with a suitable fallback, and allow the cluster to stabilize.",
            "title": "Stabilize the Model Server Cluster"
        },
        {
            "location": "/model_monitor/#optimize-performance",
            "text": "Large batch sizes provide higher throughput at the expense of latency.  PipelineAI dynamically configures the system to find the proper balance.",
            "title": "Optimize Performance"
        },
        {
            "location": "/model_monitor/#control-latency-with-timeouts",
            "text": "High latency may lead to unhealthy model servers if left unbounded.  All PipelineAI service calls are bound with timeouts.",
            "title": "Control Latency with Timeouts"
        },
        {
            "location": "/model_monitor/#monitor-and-alert",
            "text": "High resource utilization - beyond container and physical node limits - will certainly degrade performance.  PipelineAI monitors all system resources.",
            "title": "Monitor and Alert"
        },
        {
            "location": "/model_monitor/#scale-dynamically",
            "text": "All PipelineAI services support auto-scaling across federated cloud and on-premise environments.",
            "title": "Scale Dynamically"
        },
        {
            "location": "/model_monitor/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/model_monitor/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/model_monitor/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/gpu/",
            "text": "GPUs and Performance\n\u00b6\n\n\nGPUs\n\u00b6\n\n\nPipelineAI supports GPUs natively throughout the entire platform.\n\n\n\n\nHere are some publically-available resources including Docker images, source code, Nvidia driver and toolkit configuration, videos, slides, and workshop materials that demonstrate PipelineAI's support for GPUs.\n\n\nGitHub Repo\n\u00b6\n\n\nfluxcapacitor/pipeline/gpu.ml\n\n\nfluxcapacitor/pipeline/package.ml\n\n\nDocker Images\n\u00b6\n\n\nGPU\n\n\nAWS (GPU) + TensorFlow + Spark + HDFS + Docker\n\n\nGoogle Cloud (GPU) + TensorFlow + Spark + HDFS + Docker\n\n\nCPU\n\n\nAWS (CPU) + TensorFlow + Spark + HDFS + Docker\n\n\nGoogle Cloud (CPU) + TensorFlow + Spark + HDFS + Docker\n\n\nPerformance\n\u00b6\n\n\nPipelineAI maintains a collection of \nDocker Images\n with many optimizations already enabled including OpenBLAS, AVX, AVX2, FMA, etc.\n\n\nGitHub Repo\n\u00b6\n\n\nfluxcapacitor/pipeline/gpu.ml\n\n\nfluxcapacitor/pipeline/package.ml\n\n\nML/AI Model Performance Optimizations\n\u00b6\n\n\nClick \nHERE\n for examples of optimizing model prediction performance with PipelineAI.\n\n\nTensorFlow Optimization Example\n\u00b6\n\n\nBefore Optimization\n\n\nThis model is very slow at prediction time.\n\n\n\n\nAfter Optimization\n\n\nThis model is \nmuch\n faster at prediction time!\n\n\n\n\nRecent \nEvents\n\u00b6\n\n\nVideos and Slides\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "GPUs"
        },
        {
            "location": "/gpu/#gpus-and-performance",
            "text": "",
            "title": "GPUs and Performance"
        },
        {
            "location": "/gpu/#gpus",
            "text": "PipelineAI supports GPUs natively throughout the entire platform.   Here are some publically-available resources including Docker images, source code, Nvidia driver and toolkit configuration, videos, slides, and workshop materials that demonstrate PipelineAI's support for GPUs.",
            "title": "GPUs"
        },
        {
            "location": "/gpu/#github-repo",
            "text": "fluxcapacitor/pipeline/gpu.ml  fluxcapacitor/pipeline/package.ml",
            "title": "GitHub Repo"
        },
        {
            "location": "/gpu/#docker-images",
            "text": "GPU  AWS (GPU) + TensorFlow + Spark + HDFS + Docker  Google Cloud (GPU) + TensorFlow + Spark + HDFS + Docker  CPU  AWS (CPU) + TensorFlow + Spark + HDFS + Docker  Google Cloud (CPU) + TensorFlow + Spark + HDFS + Docker",
            "title": "Docker Images"
        },
        {
            "location": "/gpu/#performance",
            "text": "PipelineAI maintains a collection of  Docker Images  with many optimizations already enabled including OpenBLAS, AVX, AVX2, FMA, etc.",
            "title": "Performance"
        },
        {
            "location": "/gpu/#github-repo_1",
            "text": "fluxcapacitor/pipeline/gpu.ml  fluxcapacitor/pipeline/package.ml",
            "title": "GitHub Repo"
        },
        {
            "location": "/gpu/#mlai-model-performance-optimizations",
            "text": "Click  HERE  for examples of optimizing model prediction performance with PipelineAI.",
            "title": "ML/AI Model Performance Optimizations"
        },
        {
            "location": "/gpu/#tensorflow-optimization-example",
            "text": "Before Optimization  This model is very slow at prediction time.   After Optimization  This model is  much  faster at prediction time!",
            "title": "TensorFlow Optimization Example"
        },
        {
            "location": "/gpu/#recent-events",
            "text": "Videos and Slides",
            "title": "Recent Events"
        },
        {
            "location": "/gpu/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/gpu/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/gpu/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/environments/",
            "text": "Supported Deployment Environments\n\u00b6\n\n\nAmazon Web Services (AWS)\n\u00b6\n\n\n\n\nGoogle Cloud Platform\n\u00b6\n\n\n\n\nAzure\n\u00b6\n\n\n\n\nOn-Premise\n\u00b6\n\n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Hybrid Cloud and On-Prem"
        },
        {
            "location": "/environments/#supported-deployment-environments",
            "text": "",
            "title": "Supported Deployment Environments"
        },
        {
            "location": "/environments/#amazon-web-services-aws",
            "text": "",
            "title": "Amazon Web Services (AWS)"
        },
        {
            "location": "/environments/#google-cloud-platform",
            "text": "",
            "title": "Google Cloud Platform"
        },
        {
            "location": "/environments/#azure",
            "text": "",
            "title": "Azure"
        },
        {
            "location": "/environments/#on-premise",
            "text": "",
            "title": "On-Premise"
        },
        {
            "location": "/environments/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/environments/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/environments/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/events/",
            "text": "Upcoming Events\n\u00b6\n\n\nGlobal Meetups\n\u00b6\n\n\n\n\n\n\nPipelineAI is the organizer and sponsor for the series of \nAdvanced Spark and TensorFlow Meetups\n with 20,000+ members throughout the world including the following cites:\n\n\n\n\nSan Francisco\n\n\nChicago\n\n\nNew York\n\n\nWashington DC\n\n\nLondon\n\n\nBerlin\n\n\nToronto\n\n\nMadrid \n\n\nBeijing\n\n\nChennai\n\n\nBangalore\n\n\nDubai\n\n\n\n\nIn 2016 alone, we hosted 60+ free meetup community events throughout the world.  \n\n\nWhile this dedication to the community requires a large amount of human and financial capital, we continue to push forward with close to 100 global community events planned in 2017.\n\n\nMonthly PipelineAI Community Dev Sync (Online)\n\u00b6\n\n\nEveryone is invited!\n\n\nDate/Time:  9am PT, Every Third Monday, Online.\n\n\nRegister \nHERE\n for the monthly sync  meeting.\n\n\nMore info \nHERE\n on the monthly sync meeting.\n\n\nVideos\n\u00b6\n\n\n\n\nOptimize and Deploy Distributed TensorFlow, Spark, and Scikit-Learn Models (Meetup London, May 2017)\n\n\nDeploying High Performance TensorFlow in Production with GPUs (PyData London, May 2017)\n\n\nContinuously Train & Deploy Spark ML and Tensorflow AI Models from Jupyter Notebook to Production (StartupML Conference Jan 2017)\n\n\nRecent Advancements in Data Science Workflows: From Jupyter-based Notebook to NetflixOSS-based Production (Big Data Spain Nov 2016)\n\n\nSlides\n\u00b6\n\n\n\n\nDeploying High Performance TensorFlow in Production with GPUs - Strata London - May 24, 2017\n\n\nHigh Performance TensorFlow + GPUs - GPU Tech Conference - San Jose, May 2017 (Slides)\n\n\nWorkshops\n\u00b6\n\n\nPipelineAI Distributed Spark ML + Tensorflow AI + GPU Workshop\n\u00b6\n\n\nEverybody gets their own GPU for the duration of the workshop!!\n\n\nWe will each build an end-to-end, continuous, distributed Spark ML and Tensorflow AI model training and deployment pipeline on our own GPU-based cloud instance.\n\n\nThe only prequisites are a modern browser and an internet connection. We provide the rest including a GPU-based cloud instance for each attendee.\n\n\nAt the end of the workshop, each attendee can download the Docker image and run everything in your own cloud account.\n\n\nAgenda\n\n\n\n\nSpark ML\n\n\nTensorFlow AI\n\n\nStoring and Serving Models with HDFS\n\n\nTrade-offs of CPU vs. GPU, Scale Up vs. Scale Out\n\n\nCUDA + cuDNN GPU Development Overview\n\n\nTensorFlow Model Checkpointing, Saving, Exporting, and Importing\n\n\nDistributed TensorFlow AI Model Training (Distributed Tensorflow)\n\n\nTensorFlow's Accelerated Linear Algebra Framework (XLA)\n\n\nTensorFlow's Just-in-Time (JIT) Compiler, Ahead of Time (AOT) Compiler\n\n\nCentralized Logging and Visualizing of Distributed TensorFlow Training (Tensorboard)\n\n\nDistributed Tensorflow AI Model Serving/Predicting (TensorFlow Serving)\n\n\nCentralized Logging and Metrics Collection (Prometheus, Grafana)\n\n\nContinuous TensorFow AI Model Deployment (TensorFlow, Airflow)\n\n\nHybrid Cross-Cloud and On-Premise Deployments (Kubernetes)\n\n\nHigh-Performance and Fault-Tolerant Micro-services (NetflixOSS)\n\n\n\n\nDates -- Location\n\n\nApr 22 -- San Francisco -- Spark + TensorFlow + GPUs \n(SOLD OUT)\n\n\nMay 27 -- London -- Spark + TensorFlow + GPUs \n(SOLD OUT)\n\n\nJune 10 -- New York -- Spark + TensorFlow + GPUs \n(SOLD OUT)\n\n\nJuly 8 -- San Francisco -- Spark + TensorFlow + GPUs \n(SOLD OUT)\n\n\nAug 12 -- Sydney Australia -- Spark + TensorFlow + GPUs \n(SOLD OUT)\n\n\nSept 23 -- New York and Washington DC -- Spark + TensorFlow + GPUs\n\n\nOct 28 -- London and Ireland -- Spark + TensorFlow + GPUs\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Events"
        },
        {
            "location": "/events/#upcoming-events",
            "text": "",
            "title": "Upcoming Events"
        },
        {
            "location": "/events/#global-meetups",
            "text": "PipelineAI is the organizer and sponsor for the series of  Advanced Spark and TensorFlow Meetups  with 20,000+ members throughout the world including the following cites:   San Francisco  Chicago  New York  Washington DC  London  Berlin  Toronto  Madrid   Beijing  Chennai  Bangalore  Dubai   In 2016 alone, we hosted 60+ free meetup community events throughout the world.    While this dedication to the community requires a large amount of human and financial capital, we continue to push forward with close to 100 global community events planned in 2017.",
            "title": "Global Meetups"
        },
        {
            "location": "/events/#monthly-pipelineai-community-dev-sync-online",
            "text": "Everyone is invited!  Date/Time:  9am PT, Every Third Monday, Online.  Register  HERE  for the monthly sync  meeting.  More info  HERE  on the monthly sync meeting.",
            "title": "Monthly PipelineAI Community Dev Sync (Online)"
        },
        {
            "location": "/events/#videos",
            "text": "Optimize and Deploy Distributed TensorFlow, Spark, and Scikit-Learn Models (Meetup London, May 2017)  Deploying High Performance TensorFlow in Production with GPUs (PyData London, May 2017)  Continuously Train & Deploy Spark ML and Tensorflow AI Models from Jupyter Notebook to Production (StartupML Conference Jan 2017)  Recent Advancements in Data Science Workflows: From Jupyter-based Notebook to NetflixOSS-based Production (Big Data Spain Nov 2016)",
            "title": "Videos"
        },
        {
            "location": "/events/#slides",
            "text": "Deploying High Performance TensorFlow in Production with GPUs - Strata London - May 24, 2017  High Performance TensorFlow + GPUs - GPU Tech Conference - San Jose, May 2017 (Slides)",
            "title": "Slides"
        },
        {
            "location": "/events/#workshops",
            "text": "",
            "title": "Workshops"
        },
        {
            "location": "/events/#pipelineai-distributed-spark-ml-tensorflow-ai-gpu-workshop",
            "text": "Everybody gets their own GPU for the duration of the workshop!!  We will each build an end-to-end, continuous, distributed Spark ML and Tensorflow AI model training and deployment pipeline on our own GPU-based cloud instance.  The only prequisites are a modern browser and an internet connection. We provide the rest including a GPU-based cloud instance for each attendee.  At the end of the workshop, each attendee can download the Docker image and run everything in your own cloud account.  Agenda   Spark ML  TensorFlow AI  Storing and Serving Models with HDFS  Trade-offs of CPU vs. GPU, Scale Up vs. Scale Out  CUDA + cuDNN GPU Development Overview  TensorFlow Model Checkpointing, Saving, Exporting, and Importing  Distributed TensorFlow AI Model Training (Distributed Tensorflow)  TensorFlow's Accelerated Linear Algebra Framework (XLA)  TensorFlow's Just-in-Time (JIT) Compiler, Ahead of Time (AOT) Compiler  Centralized Logging and Visualizing of Distributed TensorFlow Training (Tensorboard)  Distributed Tensorflow AI Model Serving/Predicting (TensorFlow Serving)  Centralized Logging and Metrics Collection (Prometheus, Grafana)  Continuous TensorFow AI Model Deployment (TensorFlow, Airflow)  Hybrid Cross-Cloud and On-Premise Deployments (Kubernetes)  High-Performance and Fault-Tolerant Micro-services (NetflixOSS)   Dates -- Location  Apr 22 -- San Francisco -- Spark + TensorFlow + GPUs  (SOLD OUT)  May 27 -- London -- Spark + TensorFlow + GPUs  (SOLD OUT)  June 10 -- New York -- Spark + TensorFlow + GPUs  (SOLD OUT)  July 8 -- San Francisco -- Spark + TensorFlow + GPUs  (SOLD OUT)  Aug 12 -- Sydney Australia -- Spark + TensorFlow + GPUs  (SOLD OUT)  Sept 23 -- New York and Washington DC -- Spark + TensorFlow + GPUs  Oct 28 -- London and Ireland -- Spark + TensorFlow + GPUs",
            "title": "PipelineAI Distributed Spark ML + Tensorflow AI + GPU Workshop"
        },
        {
            "location": "/events/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/events/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/events/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/training/",
            "text": "PipelineAI Training\n\u00b6\n\n\nCommunity Edition\n\u00b6\n\n\nGlobal \nEvents\n and \nWorkshops\n\n\nClick \nHERE\n to start using PipelineAI Community Edition!\n\n\nEnterprise Edition\n\u00b6\n\n\nCustom Training Available\n\n\nAccess to JumpStart Program\n\n\nContact \nsales@pipeline.io\n for more information.\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Workshops"
        },
        {
            "location": "/training/#pipelineai-training",
            "text": "",
            "title": "PipelineAI Training"
        },
        {
            "location": "/training/#community-edition",
            "text": "Global  Events  and  Workshops  Click  HERE  to start using PipelineAI Community Edition!",
            "title": "Community Edition"
        },
        {
            "location": "/training/#enterprise-edition",
            "text": "Custom Training Available  Access to JumpStart Program  Contact  sales@pipeline.io  for more information.",
            "title": "Enterprise Edition"
        },
        {
            "location": "/training/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/training/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/training/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/model_train/",
            "text": "Train Your Model\n\u00b6\n\n\nManage and Compare Experiments\n\u00b6\n\n\n\n\n\n\nSupported Model Types\n\u00b6\n\n\nScikit-Learn\n\u00b6\n\n\n\n\nR\n\u00b6\n\n\n\n\nSpark ML\n\u00b6\n\n\n\n\nTensorFlow\n\u00b6\n\n\n\n\nXGBoost\n\u00b6\n\n\n\n\nPython\n\u00b6\n\n\n\n\nJava\n\u00b6\n\n\n\n\nRecommendations\n\u00b6\n\n\n\n\nKey-Value (Redis)\n\u00b6\n\n\n\n\nKey-Value (Cassandra)\n\u00b6\n\n\n\n\nPMML\n\u00b6\n\n\n\n\nCustom Ensembles\n\u00b6\n\n\n\n\nApplications and Tools\n\u00b6\n\n\nBelow is the list of applications and tools supported by PipelineAI.  This set of tools derives from the ridiculously popular PANCAKE STACK made famous in 2016.\n\n\n\n\nAll applications and tools can be auto-scaled across both CPU and GPU nodes in all major cloud provider and on-premise environments.\n\n\n\n\n\n\n\n\nTool\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nairflow\n\n\n\n\n\n\n\n\ncassandra\n\n\n\n\n\n\n\n\nelasticsearch\n\n\n\n\n\n\n\n\nhdfs\n\n\n\n\n\n\n\n\njupyter\n\n\n\n\n\n\n\n\nkafka\n\n\n\n\n\n\n\n\nkibana\n\n\n\n\n\n\n\n\nmetastore\n\n\n\n\n\n\n\n\nmysql\n\n\n\n\n\n\n\n\npresto\n\n\n\n\n\n\n\n\nredis\n\n\n\n\n\n\n\n\nspark\n\n\n\n\n\n\n\n\nzeppelin\n\n\n\n\n\n\n\n\nzookeeper\n\n\n\n\n\n\n\n\n\n\nPipelineAI Cluster Deployment\n\u00b6\n\n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Train Your Model"
        },
        {
            "location": "/model_train/#train-your-model",
            "text": "",
            "title": "Train Your Model"
        },
        {
            "location": "/model_train/#manage-and-compare-experiments",
            "text": "",
            "title": "Manage and Compare Experiments"
        },
        {
            "location": "/model_train/#supported-model-types",
            "text": "",
            "title": "Supported Model Types"
        },
        {
            "location": "/model_train/#scikit-learn",
            "text": "",
            "title": "Scikit-Learn"
        },
        {
            "location": "/model_train/#r",
            "text": "",
            "title": "R"
        },
        {
            "location": "/model_train/#spark-ml",
            "text": "",
            "title": "Spark ML"
        },
        {
            "location": "/model_train/#tensorflow",
            "text": "",
            "title": "TensorFlow"
        },
        {
            "location": "/model_train/#xgboost",
            "text": "",
            "title": "XGBoost"
        },
        {
            "location": "/model_train/#python",
            "text": "",
            "title": "Python"
        },
        {
            "location": "/model_train/#java",
            "text": "",
            "title": "Java"
        },
        {
            "location": "/model_train/#recommendations",
            "text": "",
            "title": "Recommendations"
        },
        {
            "location": "/model_train/#key-value-redis",
            "text": "",
            "title": "Key-Value (Redis)"
        },
        {
            "location": "/model_train/#key-value-cassandra",
            "text": "",
            "title": "Key-Value (Cassandra)"
        },
        {
            "location": "/model_train/#pmml",
            "text": "",
            "title": "PMML"
        },
        {
            "location": "/model_train/#custom-ensembles",
            "text": "",
            "title": "Custom Ensembles"
        },
        {
            "location": "/model_train/#applications-and-tools",
            "text": "Below is the list of applications and tools supported by PipelineAI.  This set of tools derives from the ridiculously popular PANCAKE STACK made famous in 2016.   All applications and tools can be auto-scaled across both CPU and GPU nodes in all major cloud provider and on-premise environments.     Tool  Description      airflow     cassandra     elasticsearch     hdfs     jupyter     kafka     kibana     metastore     mysql     presto     redis     spark     zeppelin     zookeeper",
            "title": "Applications and Tools"
        },
        {
            "location": "/model_train/#pipelineai-cluster-deployment",
            "text": "",
            "title": "PipelineAI Cluster Deployment"
        },
        {
            "location": "/model_train/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/model_train/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/model_train/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/model_optimize/",
            "text": "Optimize Your Model\n\u00b6\n\n\n\n\n\n\nUpon deploying your model, PipelineAI will optimize your model for high-performance serving and predicting.\n\n\nVarious model optimization and simplification techniques include folding batch normalizations, quantizing weights, and generating native code for both CPU and GPU.\n\n\n \n\n\n\n\nExamples\n\u00b6\n\n\nTensorFlow\n\u00b6\n\n\n\n\nUnoptimized Linear Regression\n\n\n\n\nOptimized Linear Regression\n\n\n\n\nWeight Quantization\n\n\n\n\n\n\nSpark ML\n\u00b6\n\n\n\n\n \n\n\nNative Code Generation: Airbnb Price Prediction(Linear Regression)\n\n\npublic class Airbnb_Price_LinearRegressionModel {\n  public Object predict(Map<String, Object> inputs) {\n        Double bathrooms = (Double)inputs.get(\"bathrooms\");\n        Double bedrooms = (Double)inputs.get(\"bedrooms\");\n        Double square_feet = (Double)inputs.get(\"square_feet\");\n        String room_type = (String)inputs.get(\"room_type\");\n        String host_is_super_host = (String)inputs.get(\"host_is_super_host\");\n        String cancellation_policy = (String)inputs.get(\"cancellation_policy\");\n        ...        \n        Double __regressionTableNumber00 = -31.985533969928042;\n        if (room_type != null) {\n            __regressionTableNumber00 += 25.89385313144676 * ((room_type.equals(\"Entire home/apt\")) ? 1 : 0);\n        }\n        if (room_type != null) {\n            __regressionTableNumber00 += -13.556162863521244 * ((room_type.equals(\"Private room\")) ? 1 : 0);\n        }\n        if (host_is_super_host != null) {\n            __regressionTableNumber00 += -5.761601400860295 * ((host_is_super_host.equals(\"0.0\")) ? 1 : 0);\n        }\n        if (cancellation_policy != null) {\n            __regressionTableNumber00 += 2.3566340923908315 * ((cancellation_policy.equals(\"strict\")) ? 1 : \n        ...\n        price = __regressionTableNumber00;\n\n        return price;\n    }\n}\n\n\n\nNative Code Generation: Income Prediction (Decision Tree)\n\n\npublic class Census_Income_DecisionTreeModel\n    public Object predict(Map<String, Object> inputs) {\n        String income = (String)nameToValue.get(\"income\");\n        String education = (String)nameToValue.get(\"education\");\n        String marital_status = (String)nameToValue.get(\"marital_status\");\n        String occupation = (String)nameToValue.get(\"occupation\");\n        String native_country = (String)nameToValue.get(\"native_country\");\n        Integer age = (Integer)nameToValue.get(\"age\");\n        Integer education_num = (Integer)nameToValue.get(\"education_num\");\n        Integer capital_gain = (Integer)nameToValue.get(\"capital_gain\");\n        Integer capital_loss = (Integer)nameToValue.get(\"capital_loss\");\n        Integer hours_per_week = (Integer)nameToValue.get(\"hours_per_week\");\n        income = \"<=50K\";\n        Boolean __succ0 = false;\n        if (!__succ0) {\n            Integer __predicateValue1 = marital_status == null? 3 : (marital_status.equals(\"Married-civ-spouse\") ? 2 : 1);\n            if (__predicateValue1 == 1) {\n                __succ0 = true;\n                income = \"<=50K\";\n                Boolean __succ2 = false;\n                if (!__succ2) {\n                    Integer __predicateValue3 = capital_gain == null? 3 : ((capital_gain <= 7688)? 1 : 2);\n                    if (__predicateValue3 == 1) {\n                        __succ2 = true;\n                        income = \"<=50K\";\n                        Boolean __succ4 = false;\n                        if (!__succ4) {\n                            Integer __predicateValue5 = education_num == null? 3 : ((education_num <= 13)? 1 : 2);\n                            if (__predicateValue5 == 1) {\n                                __succ4 = true;\n                                income = \"<=50K\";\n                                Boolean __succ6 = false;\n        ...\n        if (!__succ0) {\n            income = null;\n            resultExplanation = null;\n        }\n\n        return income;         \n    }\n} \n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Optimize Your Model"
        },
        {
            "location": "/model_optimize/#optimize-your-model",
            "text": "Upon deploying your model, PipelineAI will optimize your model for high-performance serving and predicting.  Various model optimization and simplification techniques include folding batch normalizations, quantizing weights, and generating native code for both CPU and GPU.",
            "title": "Optimize Your Model"
        },
        {
            "location": "/model_optimize/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/model_optimize/#tensorflow",
            "text": "Unoptimized Linear Regression   Optimized Linear Regression   Weight Quantization",
            "title": "TensorFlow"
        },
        {
            "location": "/model_optimize/#spark-ml",
            "text": "Native Code Generation: Airbnb Price Prediction(Linear Regression)  public class Airbnb_Price_LinearRegressionModel {\n  public Object predict(Map<String, Object> inputs) {\n        Double bathrooms = (Double)inputs.get(\"bathrooms\");\n        Double bedrooms = (Double)inputs.get(\"bedrooms\");\n        Double square_feet = (Double)inputs.get(\"square_feet\");\n        String room_type = (String)inputs.get(\"room_type\");\n        String host_is_super_host = (String)inputs.get(\"host_is_super_host\");\n        String cancellation_policy = (String)inputs.get(\"cancellation_policy\");\n        ...        \n        Double __regressionTableNumber00 = -31.985533969928042;\n        if (room_type != null) {\n            __regressionTableNumber00 += 25.89385313144676 * ((room_type.equals(\"Entire home/apt\")) ? 1 : 0);\n        }\n        if (room_type != null) {\n            __regressionTableNumber00 += -13.556162863521244 * ((room_type.equals(\"Private room\")) ? 1 : 0);\n        }\n        if (host_is_super_host != null) {\n            __regressionTableNumber00 += -5.761601400860295 * ((host_is_super_host.equals(\"0.0\")) ? 1 : 0);\n        }\n        if (cancellation_policy != null) {\n            __regressionTableNumber00 += 2.3566340923908315 * ((cancellation_policy.equals(\"strict\")) ? 1 : \n        ...\n        price = __regressionTableNumber00;\n\n        return price;\n    }\n}  Native Code Generation: Income Prediction (Decision Tree)  public class Census_Income_DecisionTreeModel\n    public Object predict(Map<String, Object> inputs) {\n        String income = (String)nameToValue.get(\"income\");\n        String education = (String)nameToValue.get(\"education\");\n        String marital_status = (String)nameToValue.get(\"marital_status\");\n        String occupation = (String)nameToValue.get(\"occupation\");\n        String native_country = (String)nameToValue.get(\"native_country\");\n        Integer age = (Integer)nameToValue.get(\"age\");\n        Integer education_num = (Integer)nameToValue.get(\"education_num\");\n        Integer capital_gain = (Integer)nameToValue.get(\"capital_gain\");\n        Integer capital_loss = (Integer)nameToValue.get(\"capital_loss\");\n        Integer hours_per_week = (Integer)nameToValue.get(\"hours_per_week\");\n        income = \"<=50K\";\n        Boolean __succ0 = false;\n        if (!__succ0) {\n            Integer __predicateValue1 = marital_status == null? 3 : (marital_status.equals(\"Married-civ-spouse\") ? 2 : 1);\n            if (__predicateValue1 == 1) {\n                __succ0 = true;\n                income = \"<=50K\";\n                Boolean __succ2 = false;\n                if (!__succ2) {\n                    Integer __predicateValue3 = capital_gain == null? 3 : ((capital_gain <= 7688)? 1 : 2);\n                    if (__predicateValue3 == 1) {\n                        __succ2 = true;\n                        income = \"<=50K\";\n                        Boolean __succ4 = false;\n                        if (!__succ4) {\n                            Integer __predicateValue5 = education_num == null? 3 : ((education_num <= 13)? 1 : 2);\n                            if (__predicateValue5 == 1) {\n                                __succ4 = true;\n                                income = \"<=50K\";\n                                Boolean __succ6 = false;\n        ...\n        if (!__succ0) {\n            income = null;\n            resultExplanation = null;\n        }\n\n        return income;         \n    }\n}",
            "title": "Spark ML"
        },
        {
            "location": "/model_optimize/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/model_optimize/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/model_optimize/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/model_deploy/",
            "text": "Deploy Your Model\n\u00b6\n\n\n\n\n\n\nSupported Model Types\n\u00b6\n\n\nScikit-Learn\n\u00b6\n\n\n\n\nR\n\u00b6\n\n\n\n\nSpark ML\n\u00b6\n\n\n\n\nTensorFlow\n\u00b6\n\n\n\n\nXGBoost\n\u00b6\n\n\n\n\nPython\n\u00b6\n\n\n\n\nJava\n\u00b6\n\n\n\n\nRecommendations\n\u00b6\n\n\n\n\nKey-Value (Redis)\n\u00b6\n\n\n\n\nKey-Value (Cassandra)\n\u00b6\n\n\n\n\nPMML\n\u00b6\n\n\n\n\nCustom Ensembles\n\u00b6\n\n\n\n\nExamples\n\u00b6\n\n\ngit clone https://github.com/fluxcapacitor/source.ml\n\n\n\n\nNote: You can use the same \nmodel-server-url\n from the the PipelineAI \nCommunity Edition\n.  See the Community Edition example \nnotebooks\n for complete, end-to-end examples.\n\n\nTensorFlow\n\u00b6\n\n\n\n\nmodel_type: \ntensorflow\n\n\nInitialize Model\n\npio init-model --model-server-url http://your.model.server.com \\\n               --model-type tensorflow \\\n               --model-namespace default \\\n               --model-name tensorflow_linear \\\n               --model-version 0 \\\n               --model-path ./source.ml/prediction.ml/model_store/tensorflow/default/tensorflow_linear/0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/tensorflow/default/tensorflow_linear/0/test_inputs.txt\n\n\n\nDeploy Model\n\npio deploy\n\n\n\nPredict Model\n\npio predict\n\n\n\nScikit-Learn\n\u00b6\n\n\n\n\nmodel_type: \nscikit\n\n\nInitialize Model\n\npio init-model --model-server-url http://your.model.server.com \\\n               --model-type scikit \\\n               --model-namespace default \\\n               --model-name scikit_linear \\\n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/scikit/default/scikit_linear/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/scikit/default/scikit_linear/v0/test_inputs.txt\n\n\n\nDeploy Model\n\npio deploy\n\n\n\nPredict Model\n\npio predict\n\n\n\nSpark ML\n\u00b6\n\n\n\n\nmodel_type: \nspark\n\n\nInitialize Model\n\npio init-model --model-server-url http://your.model.server.com \\\n               --model-type spark \\\n               --model-namespace default \\\n               --model-name spark_airbnb \n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/spark/default/spark_airbnb/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/spark/default/spark_airbnb/v0/test_inputs.txt\n\n\n\nDeploy Model (CLI)\n\npio deploy\n\n\n\nDeploy Model (REST)\n\nimport\n \nrequests\n\n\n\ndeploy_url\n \n=\n \n'http://your.model.server.com/api/v1/model/deploy/spark/default/spark_airbnb/v0'\n\n\n\nfiles\n \n=\n \n{\n'file'\n:\n \nopen\n(\n'model.spark'\n,\n \n'rb'\n)}\n\n\n\nresponse\n \n=\n \nrequests\n.\npost\n(\ndeploy_url\n,\n \nfiles\n=\nfiles\n)\n\n\n\nprint\n(\n\"Success!\n\\n\\n\n%s\n\"\n \n%\n \nresponse\n.\ntext\n)\n\n\n\n\nPredict Model (CLI)\n\npio predict\n\n\n\nPredict Model (REST)\n\nimport\n \njson\n\n\n\ndata\n \n=\n \n{\n\"bathrooms\"\n:\n2.0\n,\n\n        \n\"bedrooms\"\n:\n2.0\n,\n\n        \n\"security_deposit\"\n:\n175.00\n,\n\n        \n\"cleaning_fee\"\n:\n25.0\n,\n\n        \n\"extra_people\"\n:\n1.0\n,\n\n        \n\"number_of_reviews\"\n:\n \n2.0\n,\n\n        \n\"square_feet\"\n:\n \n250.0\n,\n\n        \n\"review_scores_rating\"\n:\n \n2.0\n,\n\n        \n\"room_type\"\n:\n \n\"Entire home/apt\"\n,\n\n        \n\"host_is_super_host\"\n:\n \n\"0.0\"\n,\n\n        \n\"cancellation_policy\"\n:\n \n\"flexible\"\n,\n\n        \n\"instant_bookable\"\n:\n \n\"1.0\"\n,\n\n        \n\"state\"\n:\n \n\"CA\"\n \n}\n\n\n\njson_data\n \n=\n \njson\n.\ndumps\n(\ndata\n)\n\n\n\nwith\n \nopen\n(\n'test_inputs.json'\n,\n \n'wt'\n)\n \nas\n \nfh\n:\n\n    \nfh\n.\nwrite\n(\njson_data\n)\n\n\n\n\npredict_url = 'http://your.model.server.com/api/v1/model/predict/spark/default/spark_airbnb/v0'\n\nheaders = {'content-type': 'application/json'}\n\nresponse = requests.post(predict_url,\n                         data=json_data,\n                         headers=headers)\n\nprint(\"Response:\\n\\n%s\" % response.text)\n\n\n\nPython3\n\u00b6\n\n\n\n\nmodel_type: \npython3\n\n\nInitialize Model\n\npio init-model --model-server-url http://your.model.server.com \\\n               --model-type python3 \\\n               --model-namespace default \\\n               --model-name python3_zscore \\\n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/python3/default/python3_zscore/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/python3/default/python3_zscore/v0/test_inputs.txt\n\n\n\nDeploy Model\n\npio deploy\n\n\n\nPredict Model\n\npio predict\n\n\n\nPMML\n\u00b6\n\n\n\n\nmodel_type: \npmml\n\n\nInitialize Model\n\npio init-model --model-server-url http://your.model.server.com \\\n               --model-type pmml \\\n               --model-namespace default \\\n               --model-name pmml_airbnb \\\n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/pmml/default/pmml_airbnb/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/pmml/default/pmml_airbnb/v0/test_inputs.txt\n\n\n\nDeploy Model\n\npio deploy\n\n\n\nPredict Model\n\npio predict\n\n\n\nDeployment Workflow\n\u00b6\n\n\nPipelineAI uses python-based Airflow for pipeline workflow management.\n\npio flow\n\n\n\nUpgrade\n\u00b6\n\n\nPipelineAI supports rolling upgrades.\n\npio upgrade\n\n\n\nCanary Deploy\n\u00b6\n\n\nPipelineAI supports various canary deployment strategies including traffic-splitting and traffic-shadowing.\n\npio canary\n\n\n\nTraffic Splitting\n\u00b6\n\n\nTraffic Shadowing\n\u00b6\n\n\nRollback\n\u00b6\n\n\nPipelineAI supports rolling back to any previous revision.\n\npio rollback --revision=1\n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Deploy Your Model"
        },
        {
            "location": "/model_deploy/#deploy-your-model",
            "text": "",
            "title": "Deploy Your Model"
        },
        {
            "location": "/model_deploy/#supported-model-types",
            "text": "",
            "title": "Supported Model Types"
        },
        {
            "location": "/model_deploy/#scikit-learn",
            "text": "",
            "title": "Scikit-Learn"
        },
        {
            "location": "/model_deploy/#r",
            "text": "",
            "title": "R"
        },
        {
            "location": "/model_deploy/#spark-ml",
            "text": "",
            "title": "Spark ML"
        },
        {
            "location": "/model_deploy/#tensorflow",
            "text": "",
            "title": "TensorFlow"
        },
        {
            "location": "/model_deploy/#xgboost",
            "text": "",
            "title": "XGBoost"
        },
        {
            "location": "/model_deploy/#python",
            "text": "",
            "title": "Python"
        },
        {
            "location": "/model_deploy/#java",
            "text": "",
            "title": "Java"
        },
        {
            "location": "/model_deploy/#recommendations",
            "text": "",
            "title": "Recommendations"
        },
        {
            "location": "/model_deploy/#key-value-redis",
            "text": "",
            "title": "Key-Value (Redis)"
        },
        {
            "location": "/model_deploy/#key-value-cassandra",
            "text": "",
            "title": "Key-Value (Cassandra)"
        },
        {
            "location": "/model_deploy/#pmml",
            "text": "",
            "title": "PMML"
        },
        {
            "location": "/model_deploy/#custom-ensembles",
            "text": "",
            "title": "Custom Ensembles"
        },
        {
            "location": "/model_deploy/#examples",
            "text": "git clone https://github.com/fluxcapacitor/source.ml  Note: You can use the same  model-server-url  from the the PipelineAI  Community Edition .  See the Community Edition example  notebooks  for complete, end-to-end examples.",
            "title": "Examples"
        },
        {
            "location": "/model_deploy/#tensorflow_1",
            "text": "model_type:  tensorflow  Initialize Model pio init-model --model-server-url http://your.model.server.com \\\n               --model-type tensorflow \\\n               --model-namespace default \\\n               --model-name tensorflow_linear \\\n               --model-version 0 \\\n               --model-path ./source.ml/prediction.ml/model_store/tensorflow/default/tensorflow_linear/0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/tensorflow/default/tensorflow_linear/0/test_inputs.txt  Deploy Model pio deploy  Predict Model pio predict",
            "title": "TensorFlow"
        },
        {
            "location": "/model_deploy/#scikit-learn_1",
            "text": "model_type:  scikit  Initialize Model pio init-model --model-server-url http://your.model.server.com \\\n               --model-type scikit \\\n               --model-namespace default \\\n               --model-name scikit_linear \\\n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/scikit/default/scikit_linear/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/scikit/default/scikit_linear/v0/test_inputs.txt  Deploy Model pio deploy  Predict Model pio predict",
            "title": "Scikit-Learn"
        },
        {
            "location": "/model_deploy/#spark-ml_1",
            "text": "model_type:  spark  Initialize Model pio init-model --model-server-url http://your.model.server.com \\\n               --model-type spark \\\n               --model-namespace default \\\n               --model-name spark_airbnb \n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/spark/default/spark_airbnb/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/spark/default/spark_airbnb/v0/test_inputs.txt  Deploy Model (CLI) pio deploy  Deploy Model (REST) import   requests  deploy_url   =   'http://your.model.server.com/api/v1/model/deploy/spark/default/spark_airbnb/v0'  files   =   { 'file' :   open ( 'model.spark' ,   'rb' )}  response   =   requests . post ( deploy_url ,   files = files )  print ( \"Success! \\n\\n %s \"   %   response . text )   Predict Model (CLI) pio predict  Predict Model (REST) import   json  data   =   { \"bathrooms\" : 2.0 , \n         \"bedrooms\" : 2.0 , \n         \"security_deposit\" : 175.00 , \n         \"cleaning_fee\" : 25.0 , \n         \"extra_people\" : 1.0 , \n         \"number_of_reviews\" :   2.0 , \n         \"square_feet\" :   250.0 , \n         \"review_scores_rating\" :   2.0 , \n         \"room_type\" :   \"Entire home/apt\" , \n         \"host_is_super_host\" :   \"0.0\" , \n         \"cancellation_policy\" :   \"flexible\" , \n         \"instant_bookable\" :   \"1.0\" , \n         \"state\" :   \"CA\"   }  json_data   =   json . dumps ( data )  with   open ( 'test_inputs.json' ,   'wt' )   as   fh : \n     fh . write ( json_data )   predict_url = 'http://your.model.server.com/api/v1/model/predict/spark/default/spark_airbnb/v0'\n\nheaders = {'content-type': 'application/json'}\n\nresponse = requests.post(predict_url,\n                         data=json_data,\n                         headers=headers)\n\nprint(\"Response:\\n\\n%s\" % response.text)",
            "title": "Spark ML"
        },
        {
            "location": "/model_deploy/#python3",
            "text": "model_type:  python3  Initialize Model pio init-model --model-server-url http://your.model.server.com \\\n               --model-type python3 \\\n               --model-namespace default \\\n               --model-name python3_zscore \\\n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/python3/default/python3_zscore/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/python3/default/python3_zscore/v0/test_inputs.txt  Deploy Model pio deploy  Predict Model pio predict",
            "title": "Python3"
        },
        {
            "location": "/model_deploy/#pmml_1",
            "text": "model_type:  pmml  Initialize Model pio init-model --model-server-url http://your.model.server.com \\\n               --model-type pmml \\\n               --model-namespace default \\\n               --model-name pmml_airbnb \\\n               --model-version v0 \\\n               --model-path ./source.ml/prediction.ml/model_store/pmml/default/pmml_airbnb/v0 \\\n               --model-test-request-path ./source.ml/prediction.ml/model_store/pmml/default/pmml_airbnb/v0/test_inputs.txt  Deploy Model pio deploy  Predict Model pio predict",
            "title": "PMML"
        },
        {
            "location": "/model_deploy/#deployment-workflow",
            "text": "PipelineAI uses python-based Airflow for pipeline workflow management. pio flow",
            "title": "Deployment Workflow"
        },
        {
            "location": "/model_deploy/#upgrade",
            "text": "PipelineAI supports rolling upgrades. pio upgrade",
            "title": "Upgrade"
        },
        {
            "location": "/model_deploy/#canary-deploy",
            "text": "PipelineAI supports various canary deployment strategies including traffic-splitting and traffic-shadowing. pio canary",
            "title": "Canary Deploy"
        },
        {
            "location": "/model_deploy/#traffic-splitting",
            "text": "",
            "title": "Traffic Splitting"
        },
        {
            "location": "/model_deploy/#traffic-shadowing",
            "text": "",
            "title": "Traffic Shadowing"
        },
        {
            "location": "/model_deploy/#rollback",
            "text": "PipelineAI supports rolling back to any previous revision. pio rollback --revision=1",
            "title": "Rollback"
        },
        {
            "location": "/model_deploy/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/model_deploy/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/model_deploy/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/model_monitor/",
            "text": "Dashboards and Visualizations\n\u00b6\n\n\nMetrics, dashboards, and visualizations are native to PipelineAI.  \n\n\nWe believe that you should have full insight into everything deployed to production.\n\n\nPipelineAI provides the usual dashboards for real-time system metrics including memory usage, disk I/O and network throughput, CPU and GPU utilization of your model training and deployment activities.\n\n\nIn addition, PipelineAI provides dashboards for real-time prediction metrics including accuracy, latency, and throughput of your models in production.\n\n\nExample Dashboards\n\u00b6\n\n\nMonitor and Optimize Model Training\n\u00b6\n\n\n\n\n\n\nStabilize the Model Server Cluster\n\u00b6\n\n\nUnhealthy or latent model servers may open a \ncircuit\n, respond with a suitable fallback, and allow the cluster to stabilize.\n\n\n\n\nOptimize Performance\n\u00b6\n\n\nLarge batch sizes provide higher throughput at the expense of latency.  PipelineAI dynamically configures the system to find the proper balance.\n\n\n\n\nControl Latency with Timeouts\n\u00b6\n\n\nHigh latency may lead to unhealthy model servers if left unbounded.  All PipelineAI service calls are bound with timeouts.\n\n\nMonitor and Alert\n\u00b6\n\n\nHigh resource utilization - beyond container and physical node limits - will certainly degrade performance.  PipelineAI monitors all system resources.\n\n\nScale Dynamically\n\u00b6\n\n\nAll PipelineAI services support auto-scaling across federated cloud and on-premise environments.\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Monitor Your Model"
        },
        {
            "location": "/model_monitor/#dashboards-and-visualizations",
            "text": "Metrics, dashboards, and visualizations are native to PipelineAI.    We believe that you should have full insight into everything deployed to production.  PipelineAI provides the usual dashboards for real-time system metrics including memory usage, disk I/O and network throughput, CPU and GPU utilization of your model training and deployment activities.  In addition, PipelineAI provides dashboards for real-time prediction metrics including accuracy, latency, and throughput of your models in production.",
            "title": "Dashboards and Visualizations"
        },
        {
            "location": "/model_monitor/#example-dashboards",
            "text": "",
            "title": "Example Dashboards"
        },
        {
            "location": "/model_monitor/#monitor-and-optimize-model-training",
            "text": "",
            "title": "Monitor and Optimize Model Training"
        },
        {
            "location": "/model_monitor/#stabilize-the-model-server-cluster",
            "text": "Unhealthy or latent model servers may open a  circuit , respond with a suitable fallback, and allow the cluster to stabilize.",
            "title": "Stabilize the Model Server Cluster"
        },
        {
            "location": "/model_monitor/#optimize-performance",
            "text": "Large batch sizes provide higher throughput at the expense of latency.  PipelineAI dynamically configures the system to find the proper balance.",
            "title": "Optimize Performance"
        },
        {
            "location": "/model_monitor/#control-latency-with-timeouts",
            "text": "High latency may lead to unhealthy model servers if left unbounded.  All PipelineAI service calls are bound with timeouts.",
            "title": "Control Latency with Timeouts"
        },
        {
            "location": "/model_monitor/#monitor-and-alert",
            "text": "High resource utilization - beyond container and physical node limits - will certainly degrade performance.  PipelineAI monitors all system resources.",
            "title": "Monitor and Alert"
        },
        {
            "location": "/model_monitor/#scale-dynamically",
            "text": "All PipelineAI services support auto-scaling across federated cloud and on-premise environments.",
            "title": "Scale Dynamically"
        },
        {
            "location": "/model_monitor/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/model_monitor/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/model_monitor/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/model_experiment/",
            "text": "Experiment With Your Models\n\u00b6\n\n\nA/B Testing\n\u00b6\n\n\n\n\nMulti-armed Bandit Testing\n\u00b6\n\n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Experiment With Your Models"
        },
        {
            "location": "/model_experiment/#experiment-with-your-models",
            "text": "",
            "title": "Experiment With Your Models"
        },
        {
            "location": "/model_experiment/#ab-testing",
            "text": "",
            "title": "A/B Testing"
        },
        {
            "location": "/model_experiment/#multi-armed-bandit-testing",
            "text": "",
            "title": "Multi-armed Bandit Testing"
        },
        {
            "location": "/model_experiment/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/model_experiment/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/model_experiment/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/model_stream/",
            "text": "Stream Your Models\n\u00b6\n\n\nPipelineAI integrates with popular streaming tools such as Kafka, Kinesis, Spark Streaming, Flink Streaming, Storm, and Huron.\n\n\n \n\n\n \nAWS Kinesis\n\n\nContinuous Model Predictions\n\u00b6\n\n\nPipelineAI's modular design allows your REST-based models to run natively within Kafka and Kinesis streams for continuous model predictions.\n\n\nIncremental Model Training\n\u00b6\n\n\nPipelineAI supports continuous, incremental model training.  This is best described by Scikit-learn's \npartial_fit()\n functionality.\n\n\nContinuous Model Deployments\n\u00b6\n\n\n\n\nVideos\n\u00b6\n\n\nStartupML, Jan 2017\n  \n\n\nBig Data Spain Keynote, Nov 2016\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Stream Your Models"
        },
        {
            "location": "/model_stream/#stream-your-models",
            "text": "PipelineAI integrates with popular streaming tools such as Kafka, Kinesis, Spark Streaming, Flink Streaming, Storm, and Huron.       AWS Kinesis",
            "title": "Stream Your Models"
        },
        {
            "location": "/model_stream/#continuous-model-predictions",
            "text": "PipelineAI's modular design allows your REST-based models to run natively within Kafka and Kinesis streams for continuous model predictions.",
            "title": "Continuous Model Predictions"
        },
        {
            "location": "/model_stream/#incremental-model-training",
            "text": "PipelineAI supports continuous, incremental model training.  This is best described by Scikit-learn's  partial_fit()  functionality.",
            "title": "Incremental Model Training"
        },
        {
            "location": "/model_stream/#continuous-model-deployments",
            "text": "",
            "title": "Continuous Model Deployments"
        },
        {
            "location": "/model_stream/#videos",
            "text": "StartupML, Jan 2017     Big Data Spain Keynote, Nov 2016",
            "title": "Videos"
        },
        {
            "location": "/model_stream/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/model_stream/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/model_stream/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/open_source/",
            "text": "PipelineAI is \nOpen Source\n!\n\u00b6\n\n\nPipelineAI builds upon many great open source projects including Jupyter, Zeppelin, Spark, TensorFlow, ElasticSearch, Kafka, Docker, Kubernetes, Prometheus, etc.\n\n\n \n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\nPipelineAI is Global\n\u00b6\n\n\n\n\nGitHub\n\u00b6\n\n\nWe openly develop in \nGitHub\n and encourage quality contributions and feedback.\n\n\nPipelineAI\n and the extended PipelineAI global \ncommunity\n are 100% dedicated to open source development.\n\n\n\n\nDockerHub\n\u00b6\n\n\nWe store all of our open source Docker images in a public \nDockerHub\n repository.\n\n\n\n\nContribute\n and Become a Committer!\n\u00b6\n\n\nMany of our commiters, contributors, and community members are active committers and contributors to such popular open source projects as...\n\n\n\n\nApache Spark\n\n\nKafka\n\n\nNiFi\n\n\nCassandra\n\n\nArrow\n\n\nAirflow\n\n\nPresto\n\n\nTensorFlow\n\n\nKubernetes\n\n\nElasticsearch\n\n\nScikit-Learn\n\n\nR\n\n\nXgboost\n\n\nPMML\n\n\nHadoop\n\n\nMahout\n\n\nStorm\n\n\nCascading\n\n\nHive\n\n\nScala\n\n\nSbt\n\n\nMaven\n\n\nAngularJS\n\n\n\n\nInstall\n PipelineAI Open Source\n\u00b6\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "GitHub and DockerHub Repos"
        },
        {
            "location": "/open_source/#pipelineai-is-open-source",
            "text": "PipelineAI builds upon many great open source projects including Jupyter, Zeppelin, Spark, TensorFlow, ElasticSearch, Kafka, Docker, Kubernetes, Prometheus, etc.",
            "title": "PipelineAI is Open Source!"
        },
        {
            "location": "/open_source/#pipelineai-is-global",
            "text": "",
            "title": "PipelineAI is Global"
        },
        {
            "location": "/open_source/#github",
            "text": "We openly develop in  GitHub  and encourage quality contributions and feedback.  PipelineAI  and the extended PipelineAI global  community  are 100% dedicated to open source development.",
            "title": "GitHub"
        },
        {
            "location": "/open_source/#dockerhub",
            "text": "We store all of our open source Docker images in a public  DockerHub  repository.",
            "title": "DockerHub"
        },
        {
            "location": "/open_source/#contribute-and-become-a-committer",
            "text": "Many of our commiters, contributors, and community members are active committers and contributors to such popular open source projects as...   Apache Spark  Kafka  NiFi  Cassandra  Arrow  Airflow  Presto  TensorFlow  Kubernetes  Elasticsearch  Scikit-Learn  R  Xgboost  PMML  Hadoop  Mahout  Storm  Cascading  Hive  Scala  Sbt  Maven  AngularJS",
            "title": "Contribute and Become a Committer!"
        },
        {
            "location": "/open_source/#install-pipelineai-open-source",
            "text": "",
            "title": "Install PipelineAI Open Source"
        },
        {
            "location": "/open_source/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/open_source/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/open_source/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/releases/",
            "text": "PipelineAI Releases\n\u00b6\n\n\nOpen Source\n\u00b6\n\n\nv1.2.0\n\u00b6\n\n\nv1.1.0\n\u00b6\n\n\nv1.0.0\n\u00b6",
            "title": "Releases"
        },
        {
            "location": "/releases/#pipelineai-releases",
            "text": "",
            "title": "PipelineAI Releases"
        },
        {
            "location": "/releases/#open-source",
            "text": "",
            "title": "Open Source"
        },
        {
            "location": "/releases/#v120",
            "text": "",
            "title": "v1.2.0"
        },
        {
            "location": "/releases/#v110",
            "text": "",
            "title": "v1.1.0"
        },
        {
            "location": "/releases/#v100",
            "text": "",
            "title": "v1.0.0"
        },
        {
            "location": "/contribute/",
            "text": "Contribute to PipelineAI\n\u00b6\n\n\nWant to join the PipelineAI Community?  \n\n\nWe will gladly accept pull requests for implementations of popular ML/AI models, fast prediction runtimes, and flexible experimentation frameworks.\n\n\nClick \nHERE\n for the active list of outstanding PipelineAI issues and feature requests..\n\n\nCreating a Pull Request\n\u00b6\n\n\nCreate a Branch for Your Changes\n\u00b6\n\n\ngit branch <branch-name>\n\n\n\n\nVerify New Branch is Created\n\u00b6\n\n\ngit branch\n\n### EXPECTED OUTPUT ###\n* master   <-- this is current branch\n  <branch-name>\n\n\n\n\nSwitch to Your New Branch\n\u00b6\n\n\ngit checkout <branch-name>\n\n### EXPECTED OUTPUT ###\nSwitched to branch '<branch-name>'\n\n\n\n\nVerify That You're on the Branch\n\u00b6\n\n\ngit branch\n  master\n* <branch-name> <-- you are now on the new branch\n\n\n\n\nMake Your Branch Changes\n\u00b6\n\n\n...\n\n\n\n\nVerify Branch Changes\n\u00b6\n\n\ngit status\n\n\n\n\nPrepare (Add) Your Branch Changes for Commit\n\u00b6\n\n\ngit add ...\n\n\n\n\nCommit Your Branch Changes Locally\n\u00b6\n\n\ngit commit -m \"<descriptive-message>\"\n\n\n\n\nPush Your Branch Changes Remotely\n\u00b6\n\n\ngit\n \npush\n \n-\nu\n \norigin\n \n<\nbranch\n-\nname\n>\n\n\n\n### EXPECTED OUTPUT ###\n\n\n# Counting objects: 8, done.\n\n\n# Delta compression using up to 8 threads.\n\n\n# Compressing objects: 100% (6/6), done.\n\n\n# Writing objects: 100% (8/8), 684 bytes | 0 bytes/s, done.\n\n\n# Total 8 (delta 2), reused 0 (delta 0)\n\n\n# remote: Resolving deltas: 100% (2/2), completed with 1 local objects.\n\n\n# To github.com:fluxcapacitor/pipeline.git\n\n\n# * [new branch]      <branch-name> -> <branch-name>\n\n\n#Branch <branch-name> set up to track remote branch <branch-name> from origin.\n\n\n\nNote:  If you see an error related to \nPermission denied (publickey)\n or \nPlease make sure you have the correct access rights\n, follow the steps detailed \nhere\n.\n\n\nSubmit a Pull Request with Github Server UI\n\u00b6\n\n\n\n\nCompare your \n<branch-name>\n to the \nmaster\n branch on Github Server\n\n\n\n\nFix the Pull Request if Needed based on Comments\n\u00b6\n\n\nWait for Committer to Merge Pull Request (within Github UI)\n\u00b6\n\n\nDelete the Branch (from both Local and Remote Github)\n\u00b6\n\n\nGo Back to \nmaster\n Branch\n\ngit checkout master\n\n\n\nDelete Remote Branch\n\ngit push origin --delete <branch-name>\n\n\n\nDelete Local Branch\n\ngit branch -d <branch-name>\n\n\n\nLicense and Datasets\n\u00b6\n\n\n\n\nYour work should be open source under a liberal license (ie. Apache2, MIT)\n\n\nPlease use \npublic\n training and validation datasets so that others can easily replicate your work.\n\n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Become a Committer!"
        },
        {
            "location": "/contribute/#contribute-to-pipelineai",
            "text": "Want to join the PipelineAI Community?    We will gladly accept pull requests for implementations of popular ML/AI models, fast prediction runtimes, and flexible experimentation frameworks.  Click  HERE  for the active list of outstanding PipelineAI issues and feature requests..",
            "title": "Contribute to PipelineAI"
        },
        {
            "location": "/contribute/#creating-a-pull-request",
            "text": "",
            "title": "Creating a Pull Request"
        },
        {
            "location": "/contribute/#create-a-branch-for-your-changes",
            "text": "git branch <branch-name>",
            "title": "Create a Branch for Your Changes"
        },
        {
            "location": "/contribute/#verify-new-branch-is-created",
            "text": "git branch\n\n### EXPECTED OUTPUT ###\n* master   <-- this is current branch\n  <branch-name>",
            "title": "Verify New Branch is Created"
        },
        {
            "location": "/contribute/#switch-to-your-new-branch",
            "text": "git checkout <branch-name>\n\n### EXPECTED OUTPUT ###\nSwitched to branch '<branch-name>'",
            "title": "Switch to Your New Branch"
        },
        {
            "location": "/contribute/#verify-that-youre-on-the-branch",
            "text": "git branch\n  master\n* <branch-name> <-- you are now on the new branch",
            "title": "Verify That You're on the Branch"
        },
        {
            "location": "/contribute/#make-your-branch-changes",
            "text": "...",
            "title": "Make Your Branch Changes"
        },
        {
            "location": "/contribute/#verify-branch-changes",
            "text": "git status",
            "title": "Verify Branch Changes"
        },
        {
            "location": "/contribute/#prepare-add-your-branch-changes-for-commit",
            "text": "git add ...",
            "title": "Prepare (Add) Your Branch Changes for Commit"
        },
        {
            "location": "/contribute/#commit-your-branch-changes-locally",
            "text": "git commit -m \"<descriptive-message>\"",
            "title": "Commit Your Branch Changes Locally"
        },
        {
            "location": "/contribute/#push-your-branch-changes-remotely",
            "text": "git   push   - u   origin   < branch - name >  ### EXPECTED OUTPUT ###  # Counting objects: 8, done.  # Delta compression using up to 8 threads.  # Compressing objects: 100% (6/6), done.  # Writing objects: 100% (8/8), 684 bytes | 0 bytes/s, done.  # Total 8 (delta 2), reused 0 (delta 0)  # remote: Resolving deltas: 100% (2/2), completed with 1 local objects.  # To github.com:fluxcapacitor/pipeline.git  # * [new branch]      <branch-name> -> <branch-name>  #Branch <branch-name> set up to track remote branch <branch-name> from origin.  \nNote:  If you see an error related to  Permission denied (publickey)  or  Please make sure you have the correct access rights , follow the steps detailed  here .",
            "title": "Push Your Branch Changes Remotely"
        },
        {
            "location": "/contribute/#submit-a-pull-request-with-github-server-ui",
            "text": "Compare your  <branch-name>  to the  master  branch on Github Server",
            "title": "Submit a Pull Request with Github Server UI"
        },
        {
            "location": "/contribute/#fix-the-pull-request-if-needed-based-on-comments",
            "text": "",
            "title": "Fix the Pull Request if Needed based on Comments"
        },
        {
            "location": "/contribute/#wait-for-committer-to-merge-pull-request-within-github-ui",
            "text": "",
            "title": "Wait for Committer to Merge Pull Request (within Github UI)"
        },
        {
            "location": "/contribute/#delete-the-branch-from-both-local-and-remote-github",
            "text": "Go Back to  master  Branch git checkout master  Delete Remote Branch git push origin --delete <branch-name>  Delete Local Branch git branch -d <branch-name>",
            "title": "Delete the Branch (from both Local and Remote Github)"
        },
        {
            "location": "/contribute/#license-and-datasets",
            "text": "Your work should be open source under a liberal license (ie. Apache2, MIT)  Please use  public  training and validation datasets so that others can easily replicate your work.",
            "title": "License and Datasets"
        },
        {
            "location": "/contribute/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/contribute/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/contribute/#more-resources",
            "text": "",
            "title": "More Resources"
        },
        {
            "location": "/install/",
            "text": "Install PipelineAI Open Source\n\u00b6\n\n\nWhile we recommend the hosted \nPipelineAI Community Edition\n when evaluating PipelineAI, we provide installation instructions below to setup PipelineAI in your own cloud-based or on-premise environment.\n\n\nNote:  Support is limited for this offering, but we would love your feedback, bug reports, and feature requests \nHERE\n. \n\n\nPipelineAI Standalone\n\u00b6\n\n\nThe standalone PipelineAI Community Edition uses a single Docker image that can run in any CPU and GPU-based environment that supports \nDocker\n for CPUs or \nNvidia-Docker\n for GPUs.\n\n\n\n\n\n\nAWS GPU\n\u00b6\n\n\nAWS GPU\n\n\nGoogle Cloud GPU\n\u00b6\n\n\nGoogle Cloud GPU\n\n\nAWS CPU\n\u00b6\n\n\nAWS CPU\n\n\nGoogle Cloud CPU\n\u00b6\n\n\nGoogle Cloud CPU\n\n\nPipelineAI Distributed\n\u00b6\n\n\nPipelineAI uses Kubernetes for Docker Container management and orchestration.\n\n\n\n\n\n\nLocal\n\u00b6\n\n\nLocal, Mini Kubernetes Cluster + PipelineAI Community on Local Laptop or Low-Memory Server\n\n\nAWS\n\u00b6\n\n\nFull Kubernetes Cluster + PipelineAI Community on AWS.\n\n\n\n\nThis requires large instance types with at least 50 GB RAM, 8 CPUs, 100 GB Disk.\n\n\nGoogle Cloud\n\u00b6\n\n\nFull Kubernetes Cluster + PipelineAI Community on Google Cloud\n\n\n\n\nThis requires large instance types with at least 50 GB RAM, 8 CPUs, 100 GB Disk.\n\n\nAzure\n\u00b6\n\n\nFull Kubernetes Cluster + PipelineAI Community Edition on Azure\n\n\n\n\nThis requires large instance types with at least 50 GB RAM, 8 CPUs, 100 GB Disk.\n\n\nOn-Premise\n\u00b6\n\n\nFull Kubernetes Cluster + PipelineAI Community Edition On-Premise\n\n\n\n\n\n\nPipelineAI Home\n\u00b6\n\n\nRegister for PipelineAI \nEnterprise Edition\n\u00b6\n\n\n\n\n \n\n\n\n\n  #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/\n\n\n\n\n\n\n\n\n\n\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');\n\n\n\n\n\n\n\n\n\nMore Resources\n\u00b6",
            "title": "Install PipelineAI Open Source"
        },
        {
            "location": "/install/#install-pipelineai-open-source",
            "text": "While we recommend the hosted  PipelineAI Community Edition  when evaluating PipelineAI, we provide installation instructions below to setup PipelineAI in your own cloud-based or on-premise environment.  Note:  Support is limited for this offering, but we would love your feedback, bug reports, and feature requests  HERE .",
            "title": "Install PipelineAI Open Source"
        },
        {
            "location": "/install/#pipelineai-standalone",
            "text": "The standalone PipelineAI Community Edition uses a single Docker image that can run in any CPU and GPU-based environment that supports  Docker  for CPUs or  Nvidia-Docker  for GPUs.",
            "title": "PipelineAI Standalone"
        },
        {
            "location": "/install/#aws-gpu",
            "text": "AWS GPU",
            "title": "AWS GPU"
        },
        {
            "location": "/install/#google-cloud-gpu",
            "text": "Google Cloud GPU",
            "title": "Google Cloud GPU"
        },
        {
            "location": "/install/#aws-cpu",
            "text": "AWS CPU",
            "title": "AWS CPU"
        },
        {
            "location": "/install/#google-cloud-cpu",
            "text": "Google Cloud CPU",
            "title": "Google Cloud CPU"
        },
        {
            "location": "/install/#pipelineai-distributed",
            "text": "PipelineAI uses Kubernetes for Docker Container management and orchestration.",
            "title": "PipelineAI Distributed"
        },
        {
            "location": "/install/#local",
            "text": "Local, Mini Kubernetes Cluster + PipelineAI Community on Local Laptop or Low-Memory Server",
            "title": "Local"
        },
        {
            "location": "/install/#aws",
            "text": "Full Kubernetes Cluster + PipelineAI Community on AWS.   This requires large instance types with at least 50 GB RAM, 8 CPUs, 100 GB Disk.",
            "title": "AWS"
        },
        {
            "location": "/install/#google-cloud",
            "text": "Full Kubernetes Cluster + PipelineAI Community on Google Cloud   This requires large instance types with at least 50 GB RAM, 8 CPUs, 100 GB Disk.",
            "title": "Google Cloud"
        },
        {
            "location": "/install/#azure",
            "text": "Full Kubernetes Cluster + PipelineAI Community Edition on Azure   This requires large instance types with at least 50 GB RAM, 8 CPUs, 100 GB Disk.",
            "title": "Azure"
        },
        {
            "location": "/install/#on-premise",
            "text": "Full Kubernetes Cluster + PipelineAI Community Edition On-Premise",
            "title": "On-Premise"
        },
        {
            "location": "/install/#pipelineai-home",
            "text": "",
            "title": "PipelineAI Home"
        },
        {
            "location": "/install/#register-for-pipelineai-enterprise-edition",
            "text": "#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }               /*<![CDATA[*/window.zEmbed||function(e,t){var n,o,d,i,s,a=[],r=document.createElement(\"iframe\");window.zEmbed=function(){a.push(arguments)},window.zE=window.zE||window.zEmbed,r.src=\"javascript:false\",r.title=\"\",r.role=\"presentation\",(r.frameElement||r).style.cssText=\"display: none\",d=document.getElementsByTagName(\"script\"),d=d[d.length-1],d.parentNode.insertBefore(r,d),i=r.contentWindow,s=i.document;try{o=s}catch(e){n=document.domain,r.src='javascript:var d=document.open();d.domain=\"'+n+'\";void(0);',o=s}o.open()._l=function(){var e=this.createElement(\"script\");n&&(this.domain=n),e.id=\"js-iframe-async\",e.src=\"https://assets.zendesk.com/embeddable_framework/main.js\",this.t=+new Date,this.zendeskHost=\"pipelineai.zendesk.com\",this.zEQueue=a,this.body.appendChild(e)},o.write('<body onload=\"document._l();\">'),o.close()}();\n/*]]>*/    \n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n      ga('create', 'UA-78551725-1', 'auto');\n      ga('require', 'linkid');\n      ga('send', 'pageview');",
            "title": "Register for PipelineAI Enterprise Edition"
        },
        {
            "location": "/install/#more-resources",
            "text": "",
            "title": "More Resources"
        }
    ]
}